{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Download NeMo and Config files\nimport os\nif not os.path.exists('/kaggle/working/configs/config.yaml'):\n    !pip3 install num2words\n    \n    # Install dependencies\n    !pip install wget\n    !apt-get install -y sox libsndfile1 ffmpeg\n    !pip install unidecode\n    !pip install matplotlib>=3.3.2\n\n    ## Install NeMo\n    BRANCH = 'r1.8.2'\n    !python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n\n    ## Grab the config for CONFORMER-CTC-BPE\n    !mkdir configs\n    !wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/asr/conf/config.yaml\n    !wget -P configs/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/asr/conf/conformer/conformer_ctc_bpe.yaml\n    \n    ## Grab Tokenizer\n    !mkdir tokenizers\n    !wget -P tokenizers/ https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/tokenizers/process_asr_text_tokenizer.py","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-05T17:32:09.14707Z","iopub.execute_input":"2022-05-05T17:32:09.148669Z","iopub.status.idle":"2022-05-05T17:32:09.219679Z","shell.execute_reply.started":"2022-05-05T17:32:09.148604Z","shell.execute_reply":"2022-05-05T17:32:09.218487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Utility\nfrom num2words import num2words\nimport numpy as np\nimport pandas as pd \nimport random\nimport json\nimport yaml\n\n# Audio\nimport librosa\nimport IPython.display as ipd\nfrom tqdm.notebook import tqdm\n\n# Graphics \n%matplotlib inline\nimport librosa.display\nimport matplotlib.pyplot as plt\n\n# Models\nimport torch\nimport nemo\nimport nemo.collections.asr as nemo_asr\nimport pytorch_lightning as pl\nfrom sklearn.model_selection import train_test_split\n\n# Consts and Settings\nimport warnings\nwarnings.filterwarnings('ignore')\n\nSEED = 42\nPATH = '/kaggle/input/speech-to-text-russian/data/'\nPATH_TRAIN = PATH + 'train_wavs/'\nPATH_TEST = PATH + 'test_wavs/'\nPATH_WORKING = '/kaggle/working/'\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(SEED)\n\ntorch.cuda.empty_cache()\n\ncuda = torch.cuda.is_available()\ndevice_name = 'gpu' if cuda else 'cpu'\ndevice = torch.device('cuda' if cuda else 'cpu')\n\ndevice_name","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:09.222517Z","iopub.execute_input":"2022-05-05T17:32:09.222927Z","iopub.status.idle":"2022-05-05T17:32:09.256282Z","shell.execute_reply.started":"2022-05-05T17:32:09.222881Z","shell.execute_reply":"2022-05-05T17:32:09.255107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and listen to the audio file\nexample_file = PATH_TRAIN + '0.wav'\naudio, sample_rate = librosa.load(example_file)\n\nipd.Audio(example_file, rate=sample_rate)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:09.261714Z","iopub.execute_input":"2022-05-05T17:32:09.26338Z","iopub.status.idle":"2022-05-05T17:32:09.641343Z","shell.execute_reply.started":"2022-05-05T17:32:09.263326Z","shell.execute_reply":"2022-05-05T17:32:09.640341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot our example audio file's waveform\nplt.rcParams['figure.figsize'] = (20,5)\nplt.title('Waveform of Audio Example')\nplt.ylabel('Amplitude')\n\n_ = librosa.display.waveshow(audio)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:09.64392Z","iopub.execute_input":"2022-05-05T17:32:09.644545Z","iopub.status.idle":"2022-05-05T17:32:10.472851Z","shell.execute_reply.started":"2022-05-05T17:32:09.644492Z","shell.execute_reply":"2022-05-05T17:32:10.471976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get spectrogram using Librosa's Short-Time Fourier Transform (stft)\nspec = np.abs(librosa.stft(audio))\nspec_db = librosa.amplitude_to_db(spec, ref=np.max)  # Decibels\n\n# Use log scale to view frequencies\nlibrosa.display.specshow(spec_db, y_axis='log', x_axis='time')\nplt.colorbar()\nplt.title('Audio Spectrogram');","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:10.474479Z","iopub.execute_input":"2022-05-05T17:32:10.474973Z","iopub.status.idle":"2022-05-05T17:32:11.430632Z","shell.execute_reply.started":"2022-05-05T17:32:10.47493Z","shell.execute_reply":"2022-05-05T17:32:11.429763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mel_spec = librosa.feature.melspectrogram(audio, sr=sample_rate)\nmel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n\nlibrosa.display.specshow(\n    mel_spec_db, x_axis='time', y_axis='mel')\nplt.colorbar()\nplt.title('Mel Spectrogram');","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:11.432164Z","iopub.execute_input":"2022-05-05T17:32:11.432699Z","iopub.status.idle":"2022-05-05T17:32:11.97088Z","shell.execute_reply.started":"2022-05-05T17:32:11.432655Z","shell.execute_reply":"2022-05-05T17:32:11.969862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter transcription\ntrain_labels = pd.read_csv(PATH + 'train_labels.csv')\n            \n\ndef str_filter(utterance):\n    bad_symbols = set(['0','1','2','3','4','5','6','7','8','9','_','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','і','ї','ґ'])\n    utterance.strip('0123456789.- _')\n    utterance = ' '.join([num2words(i, lang='ru') if i.isdigit() else i for i in utterance.split()])\n    utterance = ''.join([c for c in utterance if c not in bad_symbols])\n    return utterance\n\ntrain_labels['Expected'] = train_labels['Expected'].apply(str_filter)\ntrain_labels.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:11.972888Z","iopub.execute_input":"2022-05-05T17:32:11.974145Z","iopub.status.idle":"2022-05-05T17:32:15.16549Z","shell.execute_reply.started":"2022-05-05T17:32:11.974087Z","shell.execute_reply":"2022-05-05T17:32:15.164292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = pd.read_csv(PATH + 'sample_submission.csv')\nsample_sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.167566Z","iopub.execute_input":"2022-05-05T17:32:15.168263Z","iopub.status.idle":"2022-05-05T17:32:15.197063Z","shell.execute_reply.started":"2022-05-05T17:32:15.168192Z","shell.execute_reply":"2022-05-05T17:32:15.196118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- Building Manifest Files --- #\ndef build_manifest(path, train_labels, manifest_path, test_mode=False):\n    output = ''\n    \n    for i, row in tqdm(train_labels.iterrows(), total=train_labels.shape[0]):\n        file_id = row['Id']\n        transcript = row['Expected' if not test_mode else 'Predicted']\n        audio_path = f\"{path}{file_id}.wav\"\n        duration = librosa.core.get_duration(filename=audio_path)\n\n        # Write the metadata to the manifest\n        metadata = {\n            \"audio_filepath\": audio_path,\n            \"duration\": duration,\n            \"text\": transcript\n        }\n\n        dump = json.dumps(metadata)\n        output += dump + '\\n'\n    \n    with open(manifest_path, 'w') as fout:\n        fout.write(output)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.200756Z","iopub.execute_input":"2022-05-05T17:32:15.201405Z","iopub.status.idle":"2022-05-05T17:32:15.212271Z","shell.execute_reply.started":"2022-05-05T17:32:15.201345Z","shell.execute_reply":"2022-05-05T17:32:15.211218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.remove(PATH_WORKING + 'manifest_train.json')\n# os.remove(PATH_WORKING + 'manifest_validation.json')\n# os.remove(PATH_WORKING + 'manifest_test.json')\n\nlabels_train, labels_val = train_test_split(train_labels, test_size=0.33, random_state=SEED)\n \ntrain_manifest = PATH_WORKING + 'manifest_train.json'\nif not os.path.exists(train_manifest):\n    build_manifest(PATH_TRAIN, labels_train, 'manifest_train.json')\n    \nval_manifest = PATH_WORKING + 'manifest_validation.json'\nif not os.path.exists(val_manifest):\n    build_manifest(PATH_TRAIN, labels_val, 'manifest_validation.json')\n\n\ntest_manifest = PATH_WORKING + 'manifest_test.json'\nif not os.path.exists(test_manifest):\n    build_manifest(PATH_TEST, sample_sub, 'manifest_test.json', test_mode=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.213961Z","iopub.execute_input":"2022-05-05T17:32:15.214506Z","iopub.status.idle":"2022-05-05T17:32:15.272964Z","shell.execute_reply.started":"2022-05-05T17:32:15.214452Z","shell.execute_reply":"2022-05-05T17:32:15.271719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check building manifest\nwith open('/kaggle/working/manifest_train.json', 'r') as fin:\n    print(json.loads(fin.read().split('\\n')[1]))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.274612Z","iopub.status.idle":"2022-05-05T17:32:15.275468Z","shell.execute_reply.started":"2022-05-05T17:32:15.275051Z","shell.execute_reply":"2022-05-05T17:32:15.275084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_variables(yaml):   \n    to_change = []\n    def rec_parse(g_key, yaml):\n        nonlocal to_change\n        if not type(yaml) is dict:\n            if type(yaml) is str and '$' in yaml:\n                to_change.append( (g_key, yaml) )\n        else:\n            for key, value in yaml.items():\n                rec_parse(g_key + [key], value)\n    \n    rec_parse([], yaml)\n    \n    for way, var in to_change: \n        # KOSTYL OVER HERE\n        var = var[2:][:-1].split('.')\n        if len(var) == 1:\n            value = yaml[var[0]]\n        elif len(var) == 2:\n            value = yaml[var[0]][var[1]]\n        elif len(var) == 3:\n            value = yaml[var[0]][var[1]][var[2]]\n            \n        if len(way) == 2:\n            yaml[way[0]][way[1]] = value\n        elif len(way) == 3:\n            yaml[way[0]][way[1]][way[2]] = value\n        elif len(way) == 4:\n            yaml[way[0]][way[1]][way[2]][way[3]] = value\n        \n    return yaml\n\n\n\nconfig_path = PATH_WORKING + 'configs/conformer_ctc_bpe.yaml'\n\n# --- Config Information ---#\ntry:\n    from ruamel.yaml import YAML\nexcept ModuleNotFoundError:\n    from ruamel_yaml import YAML\n\nyaml = YAML(typ='safe')\nwith open(config_path) as f:\n    params = yaml.load(f)\n    \nparams = parse_variables(params)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.277119Z","iopub.status.idle":"2022-05-05T17:32:15.27793Z","shell.execute_reply.started":"2022-05-05T17:32:15.27761Z","shell.execute_reply":"2022-05-05T17:32:15.277642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training with PyTorch Lightning","metadata":{}},{"cell_type":"code","source":"trainer = pl.Trainer(accelerator=device_name, max_epochs=50)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.279613Z","iopub.status.idle":"2022-05-05T17:32:15.280671Z","shell.execute_reply.started":"2022-05-05T17:32:15.280363Z","shell.execute_reply":"2022-05-05T17:32:15.280396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Building vocabulary and tokenizer model\nif not os.path.exists('/kaggle/working/tokenizer_spe_unigram_v128/tokenizer.model'):\n    !python /kaggle/working/tokenizers/process_asr_text_tokenizer.py \\\n     --manifest=\"/kaggle/working/manifest_train.json\" \\\n     --data_root=\"/kaggle/working/\" \\\n     --vocab_size=128 \\\n     --tokenizer=\"spe\" \\\n     --spe_type=\"unigram\" \\\n     --spe_character_coverage=1.0","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.282602Z","iopub.status.idle":"2022-05-05T17:32:15.283906Z","shell.execute_reply.started":"2022-05-05T17:32:15.283388Z","shell.execute_reply":"2022-05-05T17:32:15.283456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configure Model\nfrom omegaconf import DictConfig\n\n# Set DataSets\nparams['model']['train_ds']['manifest_filepath'] = train_manifest\nparams['model']['validation_ds']['manifest_filepath'] = val_manifest\nparams['model']['test_ds']['manifest_filepath'] = test_manifest\n\n# Set Tokenizer\nparams['model']['tokenizer']['dir'] = PATH_WORKING + 'tokenizer_spe_unigram_v128/'\n\n# Reduce batch_size because of memory\nbatch_size = 8\nparams['model']['train_ds']['batch_size'] = batch_size\nparams['model']['validation_ds']['batch_size'] = batch_size\nparams['model']['test_ds']['batch_size'] = batch_size\n\n#                             Models Params\n#  +-------------+---------+---------+----------+------------+-----+\n#  | Model       | d_model | n_heads | n_layers | time_masks | lr  |\n#  +=============+=========+========+===========+============+=====+\n#  | Small  (13M)|   176   |    4   |    16     |     5      | 5.0 |\n#  +-------------+---------+--------+-----------+------------+-----+\n#  | Medium (30M)|   256   |    4   |    18     |     5      | 5.0 |\n#  +-------------+---------+--------+-----------+------------+-----+\n#  | Large (121M)|   512   |    8   |    18     |     10     | 2.0 |\n#  +---------------------------------------------------------------+\n\n# Using Small model\nparams['model']['encoder']['d_model'] = 176\nparams['model']['encoder']['n_heads'] = 4\nparams['model']['encoder']['n_layers'] = 16\nparams['model']['spec_augment']['time_masks'] = 5\nparams['model']['optim']['lr'] = 5.0","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.286445Z","iopub.status.idle":"2022-05-05T17:32:15.28757Z","shell.execute_reply.started":"2022-05-05T17:32:15.287205Z","shell.execute_reply":"2022-05-05T17:32:15.287242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_asr_model = nemo_asr.models.EncDecCTCModelBPE(cfg=DictConfig(params['model']), trainer=trainer)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.289551Z","iopub.status.idle":"2022-05-05T17:32:15.290574Z","shell.execute_reply.started":"2022-05-05T17:32:15.290257Z","shell.execute_reply":"2022-05-05T17:32:15.29029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(first_asr_model)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.292631Z","iopub.status.idle":"2022-05-05T17:32:15.293672Z","shell.execute_reply.started":"2022-05-05T17:32:15.293355Z","shell.execute_reply":"2022-05-05T17:32:15.29339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first_asr_model.save_to('conformer-v1')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T17:32:15.295691Z","iopub.status.idle":"2022-05-05T17:32:15.296738Z","shell.execute_reply.started":"2022-05-05T17:32:15.296419Z","shell.execute_reply":"2022-05-05T17:32:15.296455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}